# Anomaly Detection & Reporting

This repo implements a causal, adaptive outlier detector for personal-finance transactions and produces a JSON payload with:
- the metric values that triggered each anomaly, and
- a â€œtransactionâ€ string containing date, description, amount.

It mirrors the logic used in the notebook (`data_exploration.ipynb`): adaptive z-threshold, modified z, IQR fence, refund pairing, â€œquick reversalsâ€, and last-month focus.

---

## ðŸ“‚ Project Structure

```
Case_credit_card/
â”œâ”€ analysis/
â”‚  â”œâ”€ data_exploration.ipynb         # Full exploratory analysis & metric development
â”‚  â”œâ”€ report.md                      # Report about the metrics used here
â”‚  â”œâ”€ cv_category_tx.png                # Example plot used in the report (optional)
â”œâ”€ code/
â”‚  â”œâ”€ main.py                        # Entry-point script: reads CSV and writes Section 4 JSON
â”‚  â”œâ”€ utils.py                       # Helper functions
â”‚  â”œâ”€ output.json                    # Example output (produced by main.py)
â”œâ”€ transactions.csv                  # Raw input data (date, category, amount, description/merchantâ€¦)
â”œâ”€ Test tech - Data Scientist.pdf    # Assignment/instructions
â”œâ”€ requirements.txt                  # Python package requirements for your venv
â””â”€ README.md                         # This file
```
---

## ðŸ› ï¸ Environment Setup

You can use conda (recommended) or pip.

### Option A â€” Conda

```bash
# 1) Create and activate the environment
conda create -n envname python=3.11 -y
conda activate envname

# 2) Install Python deps from requirements.txt (pip format)
pip install -r requirements.txt
```

### Option B â€” Pip / venv (no conda)

```bash
python -m venv envname
# Windows:
envname\Scripts\activate
# macOS/Linux:
source envname/bin/activate

pip install --upgrade pip
pip install -r requirements.txt
```

---

## â–¶ï¸ How to Run

From the repo root:

```bash
# Windows PowerShell example
python code\main.py --csv transactions.csv --out code\output.json
```

- `--csv`: path to the raw CSV (with `date`, `category`, `amount`; `description`/`merchant` optional).
- `--out`: path to the JSON output.

### What `main.py` does

1. read_df: loads and normalizes input (parses `date`, builds `inflow`/`outflow`, `year_month`).
2. df_tx: computes anomaly flags (causal z/modz/IQR), matches refunds, sets `effective_outflow`, and marks `reversed_quickly`.
3. latest_month_anomalies: selects the latest month, filters `outlier_status == "Valid"`, `outlier_gross == True`, `reversed_quickly == False`, and `outflow > 0`. If `description` is missing, it tries to merge from the raw file using robust keys.
4. build_payload: for each anomaly, records the triggering metric (|z|, |modz|, or IQR ratio) and a human string `YYYY-MM-DD â€” description â€” amount`. Writes JSON like:

```json
{
  "metric_name": "adaptive_outlier_rule",
  "value": [3.92, 4.31, 1.27],
  "transaction": [
    "2025-08-14 â€” Electronics Store â€” -1450.00",
    "2025-08-22 â€” Travel â€” -980.00",
    "2025-08-05 â€” Restaurants â€” -320.00"
  ]
}
```

---

## âœ… Data Requirements

- Required columns: `date`, `category`, `amount`
  - `amount` < 0 â†’ spending (outflow)
  - `amount` > 0 â†’ income (inflow)
- Optional: `description` (or equivalents like `merchant`, `memo`, `details`)

---

## ðŸ“š References

- Notebook: `data_exploration.ipynb` (full metric derivation and validations).
- PDF: `Test tech - Data Scientist.pdf` (assignment specification).
